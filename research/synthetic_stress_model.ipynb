{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic Stress Detection Model\n",
        "\n",
        "This notebook creates a realistic synthetic dataset for stress detection using physiological signals and builds an explainable model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install numpy pandas scikit-learn matplotlib seaborn shap plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import shap\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "plt.style.use(\"seaborn-v0_8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Synthetic Physiological Data\n",
        "\n",
        "We will create realistic synthetic data based on known physiological responses to stress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_stress_data(n_samples=10000, n_subjects=50):\n",
        "    \"\"\"\n",
        "    Generate realistic synthetic physiological data for stress detection.\n",
        "    \n",
        "    Stress levels:\n",
        "    0: Low stress (baseline)\n",
        "    1: Medium stress \n",
        "    2: High stress\n",
        "    \"\"\"\n",
        "    \n",
        "    data = []\n",
        "    \n",
        "    for subject_id in range(n_subjects):\n",
        "        # Subject-specific baseline characteristics\n",
        "        baseline_hr = np.random.normal(72, 8)  # Baseline heart rate\n",
        "        baseline_hrv = np.random.normal(45, 12)  # Baseline HRV (RMSSD)\n",
        "        baseline_movement = np.random.normal(0.5, 0.2)  # Baseline movement\n",
        "        \n",
        "        # Generate samples for this subject\n",
        "        for _ in range(n_samples // n_subjects):\n",
        "            # Randomly assign stress level\n",
        "            stress_level = np.random.choice([0, 1, 2], p=[0.4, 0.35, 0.25])\n",
        "            \n",
        "            # Generate physiological features based on stress level\n",
        "            if stress_level == 0:  # Low stress\n",
        "                hr = np.random.normal(baseline_hr, 5)\n",
        "                hrv_rmssd = np.random.normal(baseline_hrv, 8)\n",
        "                hrv_sdnn = np.random.normal(baseline_hrv * 1.2, 10)\n",
        "                movement = np.random.normal(baseline_movement, 0.1)\n",
        "                \n",
        "            elif stress_level == 1:  # Medium stress\n",
        "                hr = np.random.normal(baseline_hr + 15, 7)  # Increased HR\n",
        "                hrv_rmssd = np.random.normal(baseline_hrv * 0.7, 6)  # Decreased HRV\n",
        "                hrv_sdnn = np.random.normal(baseline_hrv * 0.8, 8)\n",
        "                movement = np.random.normal(baseline_movement + 0.2, 0.15)  # More movement\n",
        "                \n",
        "            else:  # High stress\n",
        "                hr = np.random.normal(baseline_hr + 25, 10)  # Much higher HR\n",
        "                hrv_rmssd = np.random.normal(baseline_hrv * 0.5, 5)  # Much lower HRV\n",
        "                hrv_sdnn = np.random.normal(baseline_hrv * 0.6, 6)\n",
        "                movement = np.random.normal(baseline_movement + 0.4, 0.2)  # Much more movement\n",
        "            \n",
        "            # Add some noise and ensure realistic ranges\n",
        "            hr = max(50, min(120, hr))  # Realistic HR range\n",
        "            hrv_rmssd = max(10, hrv_rmssd)  # Minimum HRV\n",
        "            hrv_sdnn = max(15, hrv_sdnn)  # Minimum HRV\n",
        "            movement = max(0, movement)  # Non-negative movement\n",
        "            \n",
        "            # Additional derived features\n",
        "            hr_variability = np.random.normal(hr * 0.1, 2)  # HR variability\n",
        "            stress_index = (hr / hrv_rmssd) if hrv_rmssd > 0 else 0  # Stress index\n",
        "            \n",
        "            data.append({\n",
        "                \"subject_id\": subject_id,\n",
        "                \"heart_rate\": hr,\n",
        "                \"hrv_rmssd\": hrv_rmssd,\n",
        "                \"hrv_sdnn\": hrv_sdnn,\n",
        "                \"movement_intensity\": movement,\n",
        "                \"hr_variability\": hr_variability,\n",
        "                \"stress_index\": stress_index,\n",
        "                \"stress_level\": stress_level\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Generate the dataset\n",
        "print(\"Generating synthetic stress dataset...\")\n",
        "df = generate_synthetic_stress_data(n_samples=10000, n_subjects=50)\n",
        "print(f\"Dataset created: {df.shape}\")\n",
        "print(f\"\n",
        "Stress level distribution:\")\n",
        "print(df[\"stress_level\"].value_counts().sort_index())\n",
        "print(f\"\n",
        "First few rows:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Exploration and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data overview\n",
        "print(\"=== DATASET OVERVIEW ===\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\n",
        "Feature statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(f\"\n",
        "Missing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(f\"\n",
        "Stress level distribution:\")\n",
        "stress_counts = df[\"stress_level\"].value_counts().sort_index()\n",
        "for level, count in stress_counts.items():\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"  Level {level}: {count} samples ({percentage:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the data distribution\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "features = [\"heart_rate\", \"hrv_rmssd\", \"hrv_sdnn\", \"movement_intensity\", \"hr_variability\", \"stress_index\"]\n",
        "feature_names = [\"Heart Rate (bpm)\", \"HRV RMSSD (ms)\", \"HRV SDNN (ms)\", \"Movement Intensity\", \"HR Variability\", \"Stress Index\"]\n",
        "\n",
        "for i, (feature, name) in enumerate(zip(features, feature_names)):\n",
        "    for stress_level in [0, 1, 2]:\n",
        "        data = df[df[\"stress_level\"] == stress_level][feature]\n",
        "        axes[i].hist(data, alpha=0.6, label=f\"Stress Level {stress_level}\", bins=30)\n",
        "    \n",
        "    axes[i].set_title(f\"{name} by Stress Level\")\n",
        "    axes[i].set_xlabel(name)\n",
        "    axes[i].set_ylabel(\"Frequency\")\n",
        "    axes[i].legend()\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = df.drop(\"subject_id\", axis=1).corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", center=0, \n",
        "            square=True, fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build and Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "feature_columns = [\"heart_rate\", \"hrv_rmssd\", \"hrv_sdnn\", \"movement_intensity\", \"hr_variability\", \"stress_index\"]\n",
        "X = df[feature_columns]\n",
        "y = df[\"stress_level\"]\n",
        "\n",
        "print(f\"Features: {feature_columns}\")\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\n",
        "Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\n",
        "Features scaled successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest model (good for interpretability)\n",
        "print(\"Training Random Forest model...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "y_pred_proba = rf_model.predict_proba(X_test_scaled)\n",
        "\n",
        "print(\"Model trained successfully!\")\n",
        "print(f\"\n",
        "Training accuracy: {rf_model.score(X_train_scaled, y_train):.3f}\")\n",
        "print(f\"Test accuracy: {rf_model.score(X_test_scaled, y_test):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(\"=== CLASSIFICATION REPORT ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Low Stress\", \"Medium Stress\", \"High Stress\"]))\n",
        "\n",
        "# Confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
        "            xticklabels=[\"Low\", \"Medium\", \"High\"],\n",
        "            yticklabels=[\"Low\", \"Medium\", \"High\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Stress Level\")\n",
        "plt.ylabel(\"Actual Stress Level\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Importance and Explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance from Random Forest\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"feature\": feature_columns,\n",
        "    \"importance\": rf_model.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"=== FEATURE IMPORTANCE ===\")\n",
        "print(feature_importance)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x=\"importance\", y=\"feature\", palette=\"viridis\")\n",
        "plt.title(\"Feature Importance in Stress Detection\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP values for explainability\n",
        "print(\"Computing SHAP values for model explainability...\")\n",
        "\n",
        "# Use a subset for SHAP (it can be computationally expensive)\n",
        "X_test_sample = X_test_scaled[:1000]  # Use first 1000 test samples\n",
        "\n",
        "# Create SHAP explainer\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "shap_values = explainer.shap_values(X_test_sample)\n",
        "\n",
        "# Plot SHAP summary\n",
        "plt.figure(figsize=(12, 8))\n",
        "shap.summary_plot(shap_values, X_test_sample, feature_names=feature_columns, show=False)\n",
        "plt.title(\"SHAP Summary Plot - Feature Impact on Stress Prediction\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"SHAP analysis completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Interactive Stress Level Predictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_stress_level(heart_rate, hrv_rmssd, hrv_sdnn, movement_intensity, hr_variability, stress_index):\n",
        "    \"\"\"\n",
        "    Predict stress level from physiological features\n",
        "    \"\"\"\n",
        "    # Create input array\n",
        "    input_data = np.array([[heart_rate, hrv_rmssd, hrv_sdnn, movement_intensity, hr_variability, stress_index]])\n",
        "    \n",
        "    # Scale the input\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    \n",
        "    # Make prediction\n",
        "    prediction = rf_model.predict(input_scaled)[0]\n",
        "    probabilities = rf_model.predict_proba(input_scaled)[0]\n",
        "    \n",
        "    return prediction, probabilities\n",
        "\n",
        "# Example predictions\n",
        "print(\"=== EXAMPLE PREDICTIONS ===\")\n",
        "\n",
        "# Example 1: Low stress scenario\n",
        "print(\"\n",
        "1. Low Stress Scenario:\")\n",
        "print(\"   Heart Rate: 70 bpm, HRV RMSSD: 50 ms, Movement: 0.3\")\n",
        "pred, prob = predict_stress_level(70, 50, 60, 0.3, 7, 1.4)\n",
        "print(f\"   Predicted Stress Level: {pred}\")\n",
        "print(f\"   Probabilities: Low={prob[0]:.3f}, Medium={prob[1]:.3f}, High={prob[2]:.3f}\")\n",
        "\n",
        "# Example 2: High stress scenario\n",
        "print(\"\n",
        "2. High Stress Scenario:\")\n",
        "print(\"   Heart Rate: 95 bpm, HRV RMSSD: 25 ms, Movement: 0.8\")\n",
        "pred, prob = predict_stress_level(95, 25, 30, 0.8, 12, 3.8)\n",
        "print(f\"   Predicted Stress Level: {pred}\")\n",
        "print(f\"   Probabilities: Low={prob[0]:.3f}, Medium={prob[1]:.3f}, High={prob[2]:.3f}\")\n",
        "\n",
        "# Example 3: Medium stress scenario\n",
        "print(\"\n",
        "3. Medium Stress Scenario:\")\n",
        "print(\"   Heart Rate: 85 bpm, HRV RMSSD: 35 ms, Movement: 0.6\")\n",
        "pred, prob = predict_stress_level(85, 35, 42, 0.6, 9, 2.4)\n",
        "print(f\"   Predicted Stress Level: {pred}\")\n",
        "print(f\"   Probabilities: Low={prob[0]:.3f}, Medium={prob[1]:.3f}, High={prob[2]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Interpretation and Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze what the model learned\n",
        "print(\"=== MODEL INSIGHTS ===\")\n",
        "print(\"\n",
        "1. Most Important Features for Stress Detection:\")\n",
        "for i, (_, row) in enumerate(feature_importance.iterrows(), 1):\n",
        "    print(f\"   {i}. {row[\"feature\"]}: {row[\"importance\"]:.3f}\")\n",
        "\n",
        "print(\"\n",
        "2. Physiological Patterns by Stress Level:\")\n",
        "stress_patterns = df.groupby(\"stress_level\")[feature_columns].mean()\n",
        "print(stress_patterns.round(2))\n",
        "\n",
        "print(\"\n",
        "3. Key Insights:\")\n",
        "print(\"   • Heart rate increases with stress level\")\n",
        "print(\"   • HRV (both RMSSD and SDNN) decreases with stress\")\n",
        "print(\"   • Movement intensity increases with stress\")\n",
        "print(\"   • Stress index (HR/HRV ratio) is a strong predictor\")\n",
        "\n",
        "print(\"\n",
        "4. Model Performance:\")\n",
        "print(f\"   • Overall accuracy: {rf_model.score(X_test_scaled, y_test):.1%}\")\n",
        "print(f\"   • Good at distinguishing between stress levels\")\n",
        "print(f\"   • Most confident predictions for extreme stress levels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model and scaler\n",
        "import joblib\n",
        "\n",
        "# Save model\n",
        "joblib.dump(rf_model, \"stress_detection_model.pkl\")\n",
        "joblib.dump(scaler, \"stress_detection_scaler.pkl\")\n",
        "\n",
        "print(\"Model and scaler saved successfully!\")\n",
        "print(\"Files created:\")\n",
        "print(\"  - stress_detection_model.pkl\")\n",
        "print(\"  - stress_detection_scaler.pkl\")\n",
        "\n",
        "# Create a simple usage example\n",
        "usage_example = \"\"\"\n",
        "# Load the model\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "model = joblib.load(\"stress_detection_model.pkl\")\n",
        "scaler = joblib.load(\"stress_detection_scaler.pkl\")\n",
        "\n",
        "# Predict stress level\n",
        "def predict_stress(heart_rate, hrv_rmssd, hrv_sdnn, movement_intensity, hr_variability, stress_index):\n",
        "    input_data = np.array([[heart_rate, hrv_rmssd, hrv_sdnn, movement_intensity, hr_variability, stress_index]])\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    prediction = model.predict(input_scaled)[0]\n",
        "    probabilities = model.predict_proba(input_scaled)[0]\n",
        "    return prediction, probabilities\n",
        "\n",
        "# Example usage\n",
        "pred, prob = predict_stress(85, 35, 42, 0.6, 9, 2.4)\n",
        "print(f\"Predicted stress level: {pred}\")\n",
        "print(f\"Probabilities: {prob}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"usage_example.py\", \"w\") as f:\n",
        "    f.write(usage_example)\n",
        "\n",
        "print(\"\n",
        "Usage example saved to \"usage_example.py\"\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
